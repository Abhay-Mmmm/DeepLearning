{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b60ae9de-830c-4098-a47c-d73ed92897ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c273ab1-8ea1-4768-92e4-ce9e739727fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21,22,-108,31,-2,32,34,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5efed8df-aa73-4199-9e24-d14059eec8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022358e9-31f2-4b99-975f-97c857920521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x: x>0)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7d924e1-4fce-4950-89ea-8bba859d77b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869\n",
      "1958\n",
      "2759\n",
      "2848\n",
      "3026\n",
      "2759\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.map(lambda x: x*89)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9121b929-7a7b-4ec0-bf87-9dbef243c84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1804 1722]\n",
      "[2624 2542]\n",
      "[2542 2788]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "\n",
    "tf_dataset = tf_dataset.filter(lambda x:x>0).map(lambda y: y*82).shuffle(2).batch(2)\n",
    "\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05811794-e3c9-428a-bed8-65eec328da5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3527b2e-29eb-4e0e-b23b-ffb6f3537659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\cats\\\\download (1).jpg'\n",
      "b'images\\\\cats\\\\download (2).jpg'\n",
      "b'images\\\\cats\\\\download (3).jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = tf.data.Dataset.list_files('images/*/*', shuffle=False)\n",
    "\n",
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac255096-ff40-4e1f-87f8-ec01e60fa852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'images\\\\dogs\\\\download (6).jpg'\n",
      "b'images\\\\cats\\\\download (1).jpg'\n",
      "b'images\\\\cats\\\\download.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(200)\n",
    "\n",
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26d8312-5c5a-4fa5-9eb7-f6cdaffd7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['cat','dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff996ca7-683e-4c88-baef-5795720c8448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(images_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c423eaa-a21c-43af-a036-8a97afd21a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(image_count*0.8)\n",
    "\n",
    "train_ds = images_ds.take(train_size)\n",
    "train_ds = images_ds.skip(train_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow DirectML",
   "language": "python",
   "name": "tf_dml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
